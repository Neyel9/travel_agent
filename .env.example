# Options supported are:
# 1. OpenAI
# 2. OpenRouter
# 3. Ollama
PROVIDER=

# Base URL for the OpenAI instance (default is https://api.openai.com/v1)
# OpenAI: https://api.openai.com/v1
# Ollama (example): http://localhost:11434/v1
# OpenRouter: https://openrouter.ai/api/v1
BASE_URL=

# OpenAI: https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# Open Router: Get your API Key here after registering: https://openrouter.ai/keys
# Ollama: No need to set this unless you specifically configured an API key
LLM_API_KEY=

# The LLM you want to use for the agents. Make sure this LLM supports tools (especially important if using Ollama)!
# OpenAI example: gpt-4o-mini
# OpenRouter example: anthropic/claude-3.7-sonnet
# Ollama example: qwen2.5:14b-instruct-8k
MODEL_CHOICE=

# API keys for real services (get these from the respective websites)
WEATHER_API_KEY=your_openweathermap_api_key
FLIGHT_API_KEY=your_aviationstack_api_key
HOTEL_API_KEY=your_rapidapi_key